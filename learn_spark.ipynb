{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pyspark.sql\n",
    "from pyspark.sql import SparkSession\n",
    "import findspark\n",
    "findspark.init() \n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml import feature, classification\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fichiers nécessaires si pas déjà dans le répertoire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://s3-eu-west-1.amazonaws.com/course.oc-static.com/courses/4297166/agents.json\n",
    "#!wget http://classics.mit.edu/Homer/iliad.mb.txt\n",
    "#!wget http://classics.mit.edu/Homer/odyssey.mb.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser une session Spark\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Spark tests\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commandes de base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## json et dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country_name: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lire le json, voir la structure\n",
    "agents = spark.read.json(\"agents.json\")\n",
    "agents.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------------------+------------------+------+\n",
      "|country_name|        id|          latitude|         longitude|   sex|\n",
      "+------------+----------+------------------+------------------+------+\n",
      "|       China| 227417393| 33.15219798270325|100.85840672174572|  Male|\n",
      "|       Haiti|6821129477|19.325567983697297|-72.43795260265814|Female|\n",
      "|       India|2078667700|23.645271492037235| 80.85636526088884|Female|\n",
      "|       China| 477556555| 33.45864668881662| 93.33604038078953|Female|\n",
      "|       India|1379059984|28.816938290678692|  80.7728698035823|Female|\n",
      "+------------+----------+------------------+------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Voir les5 premières lignes\n",
    "agents.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------------------+------------------+------+\n",
      "|country_name|        id|          latitude|         longitude|   sex|\n",
      "+------------+----------+------------------+------------------+------+\n",
      "|       India|2078667700|23.645271492037235| 80.85636526088884|Female|\n",
      "|       China| 477556555| 33.45864668881662| 93.33604038078953|Female|\n",
      "|       India|1379059984|28.816938290678692|  80.7728698035823|Female|\n",
      "|       India|1375733494|22.385712662257426| 77.90320433636231|Female|\n",
      "|       China| 265404548|29.447948266668902|106.56441719305467|Female|\n",
      "+------------+----------+------------------+------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtrer sur plusieurs critères\n",
    "agents.filter(agents.sex==\"Female\") \\\n",
    "    .filter(agents.latitude>20) \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+-------------------+-------------------+------+\n",
      "|    country_name|        id|           latitude|          longitude|   sex|\n",
      "+----------------+----------+-------------------+-------------------+------+\n",
      "|French Polynesia|7170821229|-15.004219445056265|-140.01650828107668|  Male|\n",
      "|   United States|2663608288|  38.34123451380646|-115.14211841078837|  Male|\n",
      "|   United States|2651719771|  37.05792617608187|-109.88579232396816|Female|\n",
      "+----------------+----------+-------------------+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ordonner, montrer les 3 premiers\n",
    "agents.orderBy(agents.longitude) \\\n",
    "    .limit(3) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de vue pour utiliser les requêtes SQL\n",
    "agents.createTempView(\"agents_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+-------------------+-------------------+------+\n",
      "|    country_name|        id|           latitude|          longitude|   sex|\n",
      "+----------------+----------+-------------------+-------------------+------+\n",
      "|French Polynesia|7170821229|-15.004219445056265|-140.01650828107668|  Male|\n",
      "|   United States|2663608288|  38.34123451380646|-115.14211841078837|  Male|\n",
      "|   United States|2651719771|  37.05792617608187|-109.88579232396816|Female|\n",
      "+----------------+----------+-------------------+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM agents_view ORDER BY longitude LIMIT 3\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[34] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir en rdd\n",
    "agents.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(country_name='China', id=227417393, latitude=33.15219798270325, longitude=100.85840672174572, sex='Male')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Montrer la première ligne\n",
    "agents.rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China 227417393\n"
     ]
    }
   ],
   "source": [
    "first_row = agents.rdd.first()\n",
    "print(first_row.country_name, first_row.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(country_name='Ambre', id=0, latitude=0, longitude=0, sex='Undefined')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création et ajout d'une nouvelle ligne au rdd\n",
    "pyspark.sql.Row(country_name=\"Ambre\", id=000, latitude=0, longitude=0, sex=\"Undefined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation d'un fichier texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation d'un ficier texte en rdd\n",
    "iliad_rdd = spark.sparkContext.textFile(\"iliad.mb.txt\") \\\n",
    "    .flatMap(lambda line: line.split()) \\\n",
    "    .map(lambda word: word.strip(\",;.?:/!\\\"'~()-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion des objets contenus dans le RDD en rows\n",
    "iliad_rows = iliad_rdd.map(lambda word: pyspark.sql.Row(word=word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[39] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iliad_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    word|\n",
      "+--------+\n",
      "|Provided|\n",
      "|      by|\n",
      "|     The|\n",
      "|Internet|\n",
      "|Classics|\n",
      "+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Création d'un df à partir des rows\n",
    "iliad = spark.createDataFrame(iliad_rows)\n",
    "iliad.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      word|\n",
      "+----------+\n",
      "|      zeal|\n",
      "|    youths|\n",
      "|     youth|\n",
      "| youselves|\n",
      "|yourselves|\n",
      "|  yourself|\n",
      "|     yours|\n",
      "|   yourelf|\n",
      "|      your|\n",
      "|  youngest|\n",
      "+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# les 10 derniers mots différents (distinct = .unique()) lorsque classés par ordre alphabétique\n",
    "iliad.distinct() \\\n",
    "    .orderBy(\"word\", ascending=False) \\\n",
    "    .show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP avec l'Iliade et l'Odyssé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But : A partir d'une ligne de texte , prédire si elle appartient à l'Iliade ou l'Odyssé.\n",
    "\n",
    "Algo : classification supervisée binaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture de l'Iliade en lignes\n",
    "iliad_lines = spark.sparkContext.textFile(\"iliad.mb.txt\") \\\n",
    "        .map(lambda line: line.split()) \\\n",
    "        .map(lambda words: [w.strip(\",;.?:/!\\\"'~()-\") for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'Antilochus', 'speared', 'Atymnius', 'driving', 'the', 'point', 'of', 'the', 'spear']\n",
      "['for', 'you', 'are', 'foremost', 'at', 'all', 'times', 'alike', 'in', 'fight', 'and', 'counsel', 'hold']\n",
      "['go', 'to', 'Ilius', 'and', 'tell', 'the', 'old', 'men', 'of', 'our', 'council', 'and', 'our', 'wives', 'to', 'pray']\n",
      "['scare', 'me', 'as', 'though', 'I', 'were', 'a', 'child', 'I', 'too', 'if', 'I', 'will', 'can', 'brag', 'and']\n",
      "['half', 'true', 'and', 'the', 'other', 'lies', 'as', 'rage', 'inspires', 'them', 'No', 'words', 'of', 'yours']\n"
     ]
    }
   ],
   "source": [
    "for line in iliad_lines.takeSample(False, 5):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idem pour l'Odyssé\n",
    "odyssey_lines = spark.sparkContext.textFile(\"odyssey.mb.txt\") \\\n",
    "        .map(lambda line: line.split()) \\\n",
    "        .map(lambda words: [w.strip(\",;.?:/!\\\"'~()-\") for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labéliser nos lignes (0 = Iliade, 1 = Odyssé) et transformer en rows\n",
    "iliad_labeled = iliad_lines.map(lambda words: pyspark.sql.Row(label=0, words=words))\n",
    "odyssey_labeled = odyssey_lines.map(lambda words: pyspark.sql.Row(label=1, words=words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union des rdd labélisés\n",
    "data = spark.createDataFrame(iliad_labeled.union(odyssey_labeled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va faire un bag of word de nos mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = feature.CountVectorizer(inputCol=\"words\", outputCol=\"bow\") \\\n",
    "    .fit(data)\n",
    "features = vectorizer.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|               words|                 bow|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|[Provided, by, Th...|(10915,[35,72,370...|\n",
      "|    0|[See, bottom, for...|(10915,[12,36,104...|\n",
      "|    0|[http://classics....|(10915,[9874],[1.0])|\n",
      "|    0|                  []|       (10915,[],[])|\n",
      "|    0|        [The, Iliad]|(10915,[72,10762]...|\n",
      "|    0|         [By, Homer]|(10915,[1613,6680...|\n",
      "|    0|                  []|       (10915,[],[])|\n",
      "|    0|                  []|       (10915,[],[])|\n",
      "|    0|[Translated, by, ...|(10915,[35,5188,5...|\n",
      "|    0|                  []|       (10915,[],[])|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation en train et test\n",
    "train, test = features.randomSplit([0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On prend un classifieur Naive Bayes et on le fit sur le train\n",
    "clf = classification.NaiveBayes(labelCol=\"label\", featuresCol=\"bow\", predictionCol=\"target_predicted\") \\\n",
    "    .fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sur le test\n",
    "predicted = clf.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7770646850194224\n"
     ]
    }
   ],
   "source": [
    "# Evaluation avec l'accuracy\n",
    "accuracy = predicted.filter(predicted.target_predicted==predicted.label).count() / float(predicted.count())\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.78\n"
     ]
    }
   ],
   "source": [
    "# ou encore\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"target_predicted\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predicted)\n",
    "\n",
    "print(f\"Accuracy = {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "caf1c2fcf97217de91eafa76b907d50f9ea378f5ffbee7f571142d119bb6a771"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
